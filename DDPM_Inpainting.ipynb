{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeT758HGhKZV"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from diffusers import UNet2DModel, DDPMScheduler\n",
        "from torchvision import transforms\n",
        "import PIL.Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List\n",
        "\n",
        "# Custom Scheduler\n",
        "@dataclass\n",
        "class CustomScheduler:\n",
        "    def __init__(self, timesteps: torch.Tensor, betas: torch.Tensor):\n",
        "        assert len(timesteps) == len(betas)\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = betas\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "        self.alphas_cumprod_prev = torch.roll(self.alphas_cumprod, 1)\n",
        "        self.alphas_cumprod_prev[0] = 1.0\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
        "        self.posterior_variance = self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n",
        "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
        "\n",
        "    @classmethod\n",
        "    def from_DDPMScheduler(cls, ddpm_scheduler: DDPMScheduler):\n",
        "        return cls(ddpm_scheduler.timesteps, ddpm_scheduler.betas)\n",
        "\n",
        "# Model wrapper\n",
        "class Model:\n",
        "    def __init__(self, model: UNet2DModel):\n",
        "        self.model = model\n",
        "\n",
        "    def to(self, device: torch.device):\n",
        "        self.model.to(device)\n",
        "        return self\n",
        "\n",
        "    def __call__(self, x, t):\n",
        "        return self.model(x, t)[\"sample\"]\n",
        "\n",
        "# Transform for outputs\n",
        "sample_to_pil = transforms.Compose([\n",
        "    transforms.Lambda(lambda t: t.squeeze(0)),\n",
        "    transforms.Lambda(lambda t: t.permute(1, 2, 0)),\n",
        "    transforms.Lambda(lambda t: (t + 1) * 127.5),\n",
        "    transforms.Lambda(lambda t: torch.clamp(t, 0, 255)),\n",
        "    transforms.Lambda(lambda t: t.cpu().detach().numpy().astype(np.uint8)),\n",
        "    transforms.ToPILImage(),\n",
        "])\n",
        "\n",
        "# Core diffusion functions\n",
        "@torch.no_grad()\n",
        "def single_reverse_step(model: Model, x: torch.Tensor, t: int, S: CustomScheduler) -> torch.Tensor:\n",
        "    mean = S.sqrt_recip_alphas[t] * (x - S.betas[t] * model(x, t) / S.sqrt_one_minus_alphas_cumprod[t])\n",
        "    if t == 0:\n",
        "        return mean\n",
        "    else:\n",
        "        noise = torch.randn_like(x) * torch.sqrt(S.posterior_variance[t])\n",
        "        return mean + noise\n",
        "\n",
        "@torch.no_grad()\n",
        "def zero_to_t(x_0: torch.Tensor, t: int, S: CustomScheduler) -> torch.Tensor:\n",
        "    if t == 0:\n",
        "        return x_0\n",
        "    else:\n",
        "        return torch.sqrt(S.alphas_cumprod[t]) * x_0 + torch.sqrt(1.0 - S.alphas_cumprod[t]) * torch.randn_like(x_0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def forward_j_steps(x_t: torch.Tensor, t: int, j: int, S: CustomScheduler) -> torch.Tensor:\n",
        "    partial_alpha_cumprod = S.alphas_cumprod[t+j] / S.alphas_cumprod[t]\n",
        "    return torch.sqrt(partial_alpha_cumprod) * x_t + torch.sqrt(1.0 - partial_alpha_cumprod) * torch.randn_like(x_t)\n",
        "\n",
        "def get_jumps(timesteps, jumps_every: int = 100, r: int = 5) -> List[int]:\n",
        "    jumps = []\n",
        "    for i in range(0, torch.max(timesteps), jumps_every):\n",
        "        jumps.extend([i] * r)\n",
        "    jumps.reverse()\n",
        "    return jumps\n",
        "\n",
        "# RePaint function\n",
        "@torch.no_grad()\n",
        "def repaint(original_data: torch.Tensor, keep_mask: torch.Tensor,\n",
        "            model: Model, scheduler: CustomScheduler, j:int=10, r:int=5) -> torch.Tensor:\n",
        "\n",
        "    jumps = get_jumps(scheduler.timesteps, r=r)\n",
        "    device = original_data.device\n",
        "    sample = torch.randn_like(original_data).to(device)\n",
        "    print(\"beginning repaint\")\n",
        "\n",
        "    for t in tqdm(scheduler.timesteps):\n",
        "        while len(jumps) > 0 and jumps[0] == t:\n",
        "            jumps = jumps[1:]\n",
        "            sample = forward_j_steps(sample, t, j, scheduler)\n",
        "            for override_t in range(t + j, t, -1):\n",
        "                sample = single_reverse_step(model, sample, override_t, scheduler)\n",
        "\n",
        "        x_known = zero_to_t(original_data, t, scheduler)\n",
        "        x_unknown = single_reverse_step(model, sample, t, scheduler)\n",
        "        sample = keep_mask * x_known + (1-keep_mask) * x_unknown\n",
        "\n",
        "    return sample\n",
        "\n",
        "# Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_id = \"google/ddpm-celebahq-256\"\n",
        "\n",
        "model = UNet2DModel.from_pretrained(model_id)\n",
        "scheduler = DDPMScheduler.from_pretrained(model_id)\n",
        "model = Model(model).to(device)\n",
        "scheduler = CustomScheduler.from_DDPMScheduler(scheduler)\n",
        "\n",
        "# Transforms for image and mask\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda t: (t * 2) - 1),\n",
        "    transforms.Lambda(lambda t: t.unsqueeze(0))\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda t: t.unsqueeze(0))\n",
        "])\n",
        "\n",
        "# Image & mask paths\n",
        "image_paths = [\"/content/celeba_00.jpg\", \"/content/celeba_01.jpg\"]\n",
        "mask_paths = [\"/content/mask_3.png\", \"/content/mask_4.png\"]\n",
        "results = []\n",
        "\n",
        "# Loop over images & masks\n",
        "for img_path in image_paths:\n",
        "    image = PIL.Image.open(img_path)\n",
        "    image_tensor = data_transform(image).to(device)\n",
        "\n",
        "    for mask_path in mask_paths:\n",
        "        mask = PIL.Image.open(mask_path)\n",
        "        mask_tensor = mask_transform(mask).to(device)\n",
        "\n",
        "        out = repaint(image_tensor, mask_tensor, model, scheduler)\n",
        "        results.append(sample_to_pil(out))\n",
        "\n",
        "# Display results\n",
        "fig, axes = plt.subplots(len(image_paths), len(mask_paths), figsize=(12, 6))\n",
        "for i in range(len(image_paths)):\n",
        "    for j in range(len(mask_paths)):\n",
        "        axes[i, j].imshow(results[i * len(mask_paths) + j])\n",
        "        axes[i, j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}